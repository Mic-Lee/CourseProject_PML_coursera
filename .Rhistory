library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
install.packages("rpart")
install.packages("rpart")
install.packages("rattle")
install.packages("randomForest")
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
rattle()
path <- getwd()
training.path <- file.path(path, "pml-training.csv")
testing.path <- file.path(path,"pml-testing.csv")
library(data.table)
training.data <- fread(training.path)
testing.data <- fread(testing.path)
inTrain <- createDataPartition(y=training.data$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
myTraining <- training.data[inTrain, ]; myTesting <- training.data[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv.tr <- nearZeroVar(myTraining, saveMetrics=TRUE)
View(nzv.tr)
myTraining <- myTraining[,nzv.tr$nzv==FALSE]
nzv.te<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv.te$nzv==FALSE]
myTraining[2, -58]
##clean var with more than 55% NAs
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .55 ) {
for(j in 1:length(training.minusNA3)) {
if( length( grep(names(myTraining[i]), names(training.minusNA3)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
myTraining <- training.minusNA
rm(training.minusNA)
myTraining <- myTraining[c(-1)]
##synchronizing processing
myTesting <- myTesting[colnames(myTraining)]
testing <- testing[colnames(myTraining[, -58])]
dim(myTesting);dim(testing)
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .55 ) {
for(j in 1:length(training.minusNA3)) {
if( length( grep(names(myTraining[i]), names(training.minusNA3)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
inTrain <- createDataPartition(y=training.data$classe, p=0.6, list=FALSE)
myTraining <- training.data[inTrain, ]
myTesting <- training.data[-inTrain, ]
dim(myTraining); dim(myTesting)
##remove NearZeroVariance variables
nzv.tr <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv.tr$nzv==FALSE]
nzv.te<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv.te$nzv==FALSE]
myTraining <- myTraining[c(-1)]
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .55 ) {
for(j in 1:length(training.minusNA3)) {
if( length( grep(names(myTraining[i]), names(training.minusNA3)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
myTraining
myTraining[, length(myTraining)]
myTraining[, 1]
dim(myTraining)
inTrain
myTraining <- training.data[inTrain, ]
myTraining <- myTraining[,nzv.tr$nzv==FALSE]
myTraining <- training.data[inTrain, ]
inTrain <- createDataPartition(y=training.data$classe, p=0.6, list=FALSE)
myTraining <- training.data[inTrain, ]
myTesting <- training.data[-inTrain, ]
dim(myTraining); dim(myTesting)
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7 ) {
for(j in 1:length(training.minusNA3)) {
if( length( grep(names(myTraining[i]), names(training.minusNA3)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7 ) {
for(j in 1:length(training.minusNA)) {
if( length( grep(names(myTraining[i]), names(training.minusNA3)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7 ) {
for(j in 1:length(training.minusNA)) {
if( length( grep(names(myTraining[i]), names(training.minusNA)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
myTraining <- as.data.frame(myTraining)
myTesting <- as.data.frame(myTesting)
training.minusNA <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7 ) {
for(j in 1:length(training.minusNA)) {
if( length( grep(names(myTraining[i]), names(training.minusNA)[j]) ) ==1)  {
training.minusNA <- training.minusNA[ , -j]
}
}
}
}
myTraining <- training.minusNA
rm(training.minusNA)
View(myTraining)
myTraining <- myTraining[,8:length(myTraining)]
View(myTraining)
nzv.tr <- nearZeroVar(myTraining, saveMetrics=TRUE)
nzv.tr$nzv==FALSE
myTraining.-nzv <- myTraining[,nzv.tr$nzv==FALSE]
myTraining_2 <- myTraining[,nzv.tr$nzv==FALSE]
View(myTraining_2)
myTraining <- myTraining[,nzv.tr$nzv==FALSE]
myTesting <- myTesting[colnames(myTraining)]
testing <- testing[colnames(myTraining[, -53])]
testing.data <- testing.data[colnames(myTraining[, -53])]
testing.data <- as.data.frame(testing.data)
testing.data <- testing.data[colnames(myTraining[, -53])]
dim(myTesting);dim(testing)
dim(myTesting);dim(testing.data)
myTraining[2, -53]
View(myTraining)
View(testing.data)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
for (i in 1:length(testing.data) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing.data)[j]) ) == 1)  {
class(testing.data[j]) <- class(myTraining[i])
}
}
}
View(testing.data)
testing <- rbind(myTraining[2, -53] , testing)
testing <- testing[-1,]
View(testing.data)
set.seed(12345)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsA1, myTesting$classe)
cmtree
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
svmfit <- svm(classe ~ ., data = myTraining, kernel = "linear", scale = T) # linear svm, scaling turned OFF
library(caret)
library(data.table)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
library(e1071)
svmfit <- svm(classe ~ ., data = myTraining, kernel = "linear", scale = T) # linear svm, scaling turned OFF
myTraining$classe = as.factor(myTraining$classe)
myTesting$classe = as.factor(myTesting$classe)
svmfit <- svm(classe ~ ., data = myTraining, kernel = "linear", scale = T) # linear svm, scaling turned OFF
print(svmfit)
plot(svmfit, inputData)
plot(svmfit, myTraining)
plot.svm(svmfit, myTraining)
compareTable <- table (myTraining$classe, predict(svmfit))  # tabulate
compareTable
plot(svmfit, myTraining$classe)
mean(myTraining$classe != predict(svmfit)) # 19.44% misclassification error
bestfitmodel <- modFitB1
modFitB1 <- randomForest(classe ~ ., data=myTraining, method = "Class")
predictionB2 <- predict(bestfitmodel, testing, type = "class")
bestfitmodel <- modFitB1
predictionB2 <- predict(bestfitmodel, testing.data, type = "class")
predictionB2
compareTable <- table (myTraining$classe, predict(svmfit));compareTable  # tabulate
